{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction to Data Science | 4022 | Dr. Bahrak & Dr. Yaghoobzadeh\n",
    "## CA3\n",
    "***\n",
    "### Amirreza Akbari | 810899045\n",
    "### Reza Baghestani | 810899046\n",
    "### Hananeh Jamali | 810899053\n",
    "***\n",
    "### 1402/01/29"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13f4fe2422f551c4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install & Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35e2a63653254a50"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "# Check if PySpark is installed\n",
    "if importlib.util.find_spec(\"pyspark\") is None:\n",
    "    # Install PySpark\n",
    "    !pip install pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import year, month\n",
    "from pyspark.sql.functions import mean, stddev\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import min, max, median, avg, format_number\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql.functions import split, explode\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T19:00:44.261800200Z",
     "start_time": "2024-04-17T19:00:44.248515500Z"
    }
   },
   "id": "f027d544812c325c",
   "execution_count": 111
  },
  {
   "cell_type": "markdown",
   "source": [
    "For better visualization of dataframes in jupyter notebooks, since they are rendered to html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5de21c3f07dc6f2c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>pre { white-space: pre !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML('<style>pre { white-space: pre !important; }</style>'))\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T19:00:44.285311600Z",
     "start_time": "2024-04-17T19:00:44.259166300Z"
    }
   },
   "id": "initial_id",
   "execution_count": 112
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Warm-Up"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ac262eea8ac8e23"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------     STEP 1     --------------------------------------------------------\n",
      "CSV file reading done!\n",
      "\n",
      "--------------------------------------------------------     STEP 2     --------------------------------------------------------\n",
      "The schema of data:\n",
      "\n",
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n",
      "\n",
      "number of dataframe rows: 1762\n",
      "\n",
      "--------------------------------------------------------     STEP 3     --------------------------------------------------------\n",
      "Records with closing price less than 500:\n",
      "\n",
      "+------------------+------------------+---------+\n",
      "|              Open|             Close|   Volume|\n",
      "+------------------+------------------+---------+\n",
      "|        213.429998|        214.009998|123432400|\n",
      "|        214.599998|        214.379993|150476200|\n",
      "|        214.379993|        210.969995|138040000|\n",
      "|            211.75|            210.58|119282800|\n",
      "|        210.299994|211.98000499999998|111902700|\n",
      "|212.79999700000002|210.11000299999998|115557400|\n",
      "|209.18999499999998|        207.720001|148614900|\n",
      "|        207.870005|        210.650002|151473000|\n",
      "|210.11000299999998|            209.43|108223500|\n",
      "|210.92999500000002|            205.93|148516900|\n",
      "|        208.330002|        215.039995|182501900|\n",
      "|        214.910006|            211.73|153038200|\n",
      "|        212.079994|        208.069996|152038600|\n",
      "|206.78000600000001|            197.75|220441900|\n",
      "|202.51000200000001|        203.070002|266424900|\n",
      "|205.95000100000001|        205.940001|466777500|\n",
      "|        206.849995|        207.880005|430642100|\n",
      "|        204.930004|        199.289995|293375600|\n",
      "|        201.079996|        192.060003|311488100|\n",
      "|192.36999699999998|        194.729998|187469100|\n",
      "+------------------+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "number of records: 1359\n",
      "\n",
      "--------------------------------------------------------     STEP 4     --------------------------------------------------------\n",
      "Records with opening price more than 200 and closing price less than 200:\n",
      "\n",
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "|      Date|              Open|      High|       Low|     Close|   Volume|         Adj Close|\n",
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "|2010-01-22|206.78000600000001|207.499996|    197.16|    197.75|220441900|         25.620401|\n",
      "|2010-01-28|        204.930004|205.500004|198.699995|199.289995|293375600|25.819922000000002|\n",
      "|2010-01-29|        201.079996|202.199995|190.250002|192.060003|311488100|         24.883208|\n",
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "number of records: 3\n",
      "\n",
      "--------------------------------------------------------     STEP 5     --------------------------------------------------------\n",
      "The dataframe with the new row \"Year\":\n",
      "\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+----+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|Year|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+----+\n",
      "|2010-01-04|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|2010|\n",
      "|2010-01-05|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|2010|\n",
      "|2010-01-06|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|2010|\n",
      "|2010-01-07|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|2010|\n",
      "|2010-01-08|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|2010|\n",
      "|2010-01-11|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|2010|\n",
      "|2010-01-12|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|2010|\n",
      "|2010-01-13|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|2010|\n",
      "|2010-01-14|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|2010|\n",
      "|2010-01-15|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|2010|\n",
      "|2010-01-19|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|2010|\n",
      "|2010-01-20|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|2010|\n",
      "|2010-01-21|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|2010|\n",
      "|2010-01-22|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|2010|\n",
      "|2010-01-25|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|2010|\n",
      "|2010-01-26|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|2010|\n",
      "|2010-01-27|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|2010|\n",
      "|2010-01-28|        204.930004|        205.500004|        198.699995|        199.289995|293375600|25.819922000000002|2010|\n",
      "|2010-01-29|        201.079996|        202.199995|        190.250002|        192.060003|311488100|         24.883208|2010|\n",
      "|2010-02-01|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|2010|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "--------------------------------------------------------     STEP 6     --------------------------------------------------------\n",
      "Minimum volumes traded for each year:\n",
      "\n",
      "+----+---------+\n",
      "|Year|minVolume|\n",
      "+----+---------+\n",
      "|2015| 13046400|\n",
      "|2013| 41888700|\n",
      "|2014| 14479600|\n",
      "|2012| 43938300|\n",
      "|2016| 11475900|\n",
      "|2010| 39373600|\n",
      "|2011| 44915500|\n",
      "+----+---------+\n",
      "\n",
      "\n",
      "--------------------------------------------------------     STEP 7     --------------------------------------------------------\n",
      "Highest \"Low Price\" for each year and month:\n",
      "+----+-----+------------------+\n",
      "|Year|Month|            maxLow|\n",
      "+----+-----+------------------+\n",
      "|2012|   10|        665.550026|\n",
      "|2010|    7|        260.300003|\n",
      "|2010|   12|        325.099991|\n",
      "|2015|    2|        131.169998|\n",
      "|2014|    4|        589.799988|\n",
      "|2015|   12|        117.809998|\n",
      "|2016|    7|            103.68|\n",
      "|2016|   11|        111.400002|\n",
      "|2012|    8| 673.5400089999999|\n",
      "|2013|    2|473.24997699999994|\n",
      "|2012|    4| 626.0000150000001|\n",
      "|2012|   12|        585.500023|\n",
      "|2014|   10|        107.209999|\n",
      "|2016|    5|             99.25|\n",
      "|2014|   12|        115.290001|\n",
      "|2013|    9|        503.479988|\n",
      "|2013|   10|        525.110016|\n",
      "|2014|    5|        628.900002|\n",
      "|2016|    2|         96.650002|\n",
      "|2013|   12| 566.4100269999999|\n",
      "+----+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "number of rows: 84\n",
      "\n",
      "--------------------------------------------------------     STEP 8     --------------------------------------------------------\n",
      "Mean High Price: 315.91\n",
      "Standard Deviation of High Price: 186.9\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--------------------------------------------------------     STEP 1     --------------------------------------------------------\")\n",
    "# Step 1: Read the CSV file\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Stocks Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = spark.read.csv(\"stocks.csv\", header=True, inferSchema=True)\n",
    "\n",
    "print(\"CSV file reading done!\")\n",
    "\n",
    "print(\"\\n--------------------------------------------------------     STEP 2     --------------------------------------------------------\")\n",
    "# Step 2: Find out about the schema of data\n",
    "\n",
    "print(\"The schema of data:\\n\")\n",
    "df.printSchema()\n",
    "print(\"\\nnumber of dataframe rows:\", df.count())\n",
    "\n",
    "print(\"\\n--------------------------------------------------------     STEP 3     --------------------------------------------------------\")\n",
    "# Step 3: Select records with closing price less than 500\n",
    "\n",
    "less_than_500_df = df.filter(df['Close'] < 500).select('Open', 'Close', 'Volume')\n",
    "print(\"Records with closing price less than 500:\\n\")\n",
    "less_than_500_df.show()\n",
    "print(\"number of records:\", less_than_500_df.count())\n",
    "\n",
    "print(\"\\n--------------------------------------------------------     STEP 4     --------------------------------------------------------\")\n",
    "# Step 4: Find out records with opening price more than 200 and closing price less than 200\n",
    "\n",
    "more_than_200_less_than_200_df = df.filter((df['Open'] > 200) & (df['Close'] < 200))\n",
    "print(\"Records with opening price more than 200 and closing price less than 200:\\n\")\n",
    "more_than_200_less_than_200_df.show()\n",
    "print(\"number of records:\", more_than_200_less_than_200_df.count())\n",
    "\n",
    "print(\"\\n--------------------------------------------------------     STEP 5     --------------------------------------------------------\")\n",
    "# Step 5: Extract the year from the date and save it in a new column\n",
    "\n",
    "df_with_year = df.withColumn('Year', year(df['Date']))\n",
    "print(\"The dataframe with the new row \\\"Year\\\":\\n\")\n",
    "df_with_year.show()\n",
    "\n",
    "print(\"\\n--------------------------------------------------------     STEP 6     --------------------------------------------------------\")\n",
    "# Step 6: For each year, show the minimum volumes traded\n",
    "\n",
    "min_volume_by_year = df_with_year.groupBy('Year').min('Volume').withColumnRenamed('min(Volume)', 'minVolume')\n",
    "print(\"Minimum volumes traded for each year:\\n\")\n",
    "min_volume_by_year.show()\n",
    "\n",
    "print(\"\\n--------------------------------------------------------     STEP 7     --------------------------------------------------------\")\n",
    "# Step 7: For each year and month, show the highest low price\n",
    "\n",
    "df_with_year_month = df.withColumn('Year', year(df['Date'])).withColumn('Month', month(df['Date']))\n",
    "max_low_price_by_year_month = df_with_year_month.groupBy('Year', 'Month').agg(max('Low').alias('maxLow'))\n",
    "print(\"Highest \\\"Low Price\\\" for each year and month:\\n\")\n",
    "max_low_price_by_year_month.show()\n",
    "print(\"\\nnumber of rows:\", max_low_price_by_year_month.count())\n",
    "\n",
    "print(\"\\n--------------------------------------------------------     STEP 8     --------------------------------------------------------\")\n",
    "# Step 8: Calculate mean and standard deviation of high price over the whole data frame\n",
    "\n",
    "mean_high_price = df.select(mean('High')).collect()[0][0]\n",
    "stddev_high_price = df.select(stddev('High')).collect()[0][0]\n",
    "print(\"Mean High Price:\", round(mean_high_price, 2))\n",
    "print(\"Standard Deviation of High Price:\", round(stddev_high_price, 2))\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T19:00:45.872594400Z",
     "start_time": "2024-04-17T19:00:44.270314400Z"
    }
   },
   "id": "f54426fc9ce9b00e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main Task"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba7820e00437472e"
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------     STEP 1     --------------------------------------------------------\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- album: string (nullable = true)\n",
      " |-- album_id: string (nullable = true)\n",
      " |-- artists: string (nullable = true)\n",
      " |-- artist_ids: string (nullable = true)\n",
      " |-- track_number: long (nullable = true)\n",
      " |-- disc_number: long (nullable = true)\n",
      " |-- explicit: boolean (nullable = true)\n",
      " |-- danceability: double (nullable = true)\n",
      " |-- energy: double (nullable = true)\n",
      " |-- key: long (nullable = true)\n",
      " |-- loudness: double (nullable = true)\n",
      " |-- mode: long (nullable = true)\n",
      " |-- speechiness: double (nullable = true)\n",
      " |-- acousticness: double (nullable = true)\n",
      " |-- instrumentalness: double (nullable = true)\n",
      " |-- liveness: double (nullable = true)\n",
      " |-- valence: double (nullable = true)\n",
      " |-- tempo: double (nullable = true)\n",
      " |-- duration_ms: long (nullable = true)\n",
      " |-- time_signature: double (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      "\n",
      "\n",
      "--------------------------------------------------------     STEP 2     --------------------------------------------------------\n",
      "Data type of column 'release_date': DateType()\n",
      "\n",
      "--------------------------------------------------------     STEP 3     --------------------------------------------------------\n",
      "\n",
      "Average Characteristics of Songs Per Year:\n",
      "+----+----------------+----------------+-------------------+----------------+----------+----------+-------------+----------+---------------+\n",
      "|year|min_danceability|max_danceability|median_danceability|avg_danceability|min_energy|max_energy|median_energy|avg_energy|avg_duration_ms|\n",
      "+----+----------------+----------------+-------------------+----------------+----------+----------+-------------+----------+---------------+\n",
      "|1950|          0.0650|          0.7820|             0.3540|          0.3613|    0.0015|    0.9620|       0.1640|    0.2412|   228,289.9317|\n",
      "|1936|          0.3440|          0.8340|             0.6580|          0.6403|    0.0463|    0.7390|       0.2120|    0.2470|   164,607.3012|\n",
      "|1951|          0.1350|          0.8260|             0.5230|          0.5097|    0.0108|    0.8630|       0.2940|    0.3305|   193,564.6571|\n",
      "|1958|          0.0000|          0.8960|             0.4300|          0.4269|    0.0020|    0.9810|       0.3020|    0.3362|   207,774.4397|\n",
      "|   0|          0.6570|          0.9570|             0.7605|          0.7655|    0.1040|    0.7200|       0.5475|    0.5016|   167,336.4000|\n",
      "|1983|          0.0000|          0.9870|             0.5440|          0.5261|    0.0017|    0.9980|       0.6180|    0.5687|   247,331.9686|\n",
      "|1972|          0.0000|          0.9210|             0.4790|          0.4711|    0.0006|    0.9880|       0.4315|    0.4414|   263,922.1146|\n",
      "|2007|          0.0000|          0.9940|             0.4990|          0.4932|    0.0000|    1.0000|       0.5210|    0.5120|   247,879.9769|\n",
      "|1979|          0.0574|          0.9560|             0.5290|          0.5134|    0.0016|    0.9970|       0.5215|    0.5052|   253,367.2550|\n",
      "|1988|          0.0000|          0.9450|             0.4300|          0.4408|    0.0000|    1.0000|       0.3450|    0.4131|   262,583.3386|\n",
      "|2014|          0.0000|          0.9860|             0.4970|          0.4865|    0.0000|    1.0000|       0.5590|    0.5357|   259,282.5934|\n",
      "|1986|          0.0000|          0.9620|             0.4850|          0.4772|    0.0001|    0.9990|       0.5020|    0.4950|   259,622.7110|\n",
      "|1908|          0.4320|          0.7550|             0.6280|          0.6041|    0.0712|    0.8100|       0.4920|    0.4737|   226,203.4737|\n",
      "|1949|          0.1120|          0.8890|             0.3570|          0.4038|    0.0137|    0.7930|       0.2510|    0.2653|   186,792.3793|\n",
      "|1969|          0.0000|          0.8990|             0.4630|          0.4574|    0.0010|    0.9970|       0.4310|    0.4321|   230,629.1010|\n",
      "|1930|          0.1590|          0.8230|             0.5940|          0.5812|    0.1160|    0.7790|       0.3630|    0.3505|   209,904.8305|\n",
      "|1967|          0.0000|          0.8490|             0.4840|          0.4703|    0.0026|    0.9500|       0.3895|    0.3957|   220,114.6943|\n",
      "|1964|          0.0000|          0.8000|             0.3960|          0.3953|    0.0032|    0.9950|       0.2680|    0.3150|   258,597.4102|\n",
      "|1956|          0.0000|          0.8900|             0.4740|          0.4564|    0.0058|    0.9950|       0.2995|    0.3496|   239,359.3209|\n",
      "|1937|          0.4900|          0.8230|             0.6680|          0.6566|    0.0643|    0.6050|       0.3135|    0.3107|   159,192.7000|\n",
      "+----+----------------+----------------+-------------------+----------------+----------+----------+-------------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "dataset excluding explicit songs:\n",
      "+--------------------+--------------------+--------------------+-----------+------------+\n",
      "|                name|               album|             artists|duration_ms|release_date|\n",
      "+--------------------+--------------------+--------------------+-----------+------------+\n",
      "|             Testify|The Battle Of Los...|['Rage Against Th...|     210133|  1999-11-02|\n",
      "|    Calm Like a Bomb|The Battle Of Los...|['Rage Against Th...|     298893|  1999-11-02|\n",
      "|Sleep Now In the ...|The Battle Of Los...|['Rage Against Th...|     205600|  1999-11-02|\n",
      "|Born of a Broken Man|The Battle Of Los...|['Rage Against Th...|     280960|  1999-11-02|\n",
      "|      Born As Ghosts|The Battle Of Los...|['Rage Against Th...|     202040|  1999-11-02|\n",
      "|               Maria|The Battle Of Los...|['Rage Against Th...|     228093|  1999-11-02|\n",
      "|Voice of the Voic...|The Battle Of Los...|['Rage Against Th...|     151573|  1999-11-02|\n",
      "|New Millennium Homes|The Battle Of Los...|['Rage Against Th...|     224933|  1999-11-02|\n",
      "| War Within a Breath|The Battle Of Los...|['Rage Against Th...|     216427|  1999-11-02|\n",
      "|  Settle for Nothing|Rage Against The ...|['Rage Against Th...|     287333|  1992-11-03|\n",
      "|             Wake Up|Rage Against The ...|['Rage Against Th...|     364133|  1992-11-03|\n",
      "|    Fistful of Steel|Rage Against The ...|['Rage Against Th...|     331107|  1992-11-03|\n",
      "|             Freedom|Rage Against The ...|['Rage Against Th...|     366267|  1992-11-03|\n",
      "|    Man on a Mission|      Do It for Love|['Daryl Hall & Jo...|     224307|  2018-04-10|\n",
      "|      Do It for Love|      Do It for Love|['Daryl Hall & Jo...|     238000|  2018-04-10|\n",
      "|  Someday We'll Know|      Do It for Love|['Daryl Hall & Jo...|     268013|  2018-04-10|\n",
      "|     Forever for You|      Do It for Love|['Daryl Hall & Jo...|     277813|  2018-04-10|\n",
      "|    Life's Too Short|      Do It for Love|['Daryl Hall & Jo...|     209960|  2018-04-10|\n",
      "|         Getaway Car|      Do It for Love|['Daryl Hall & Jo...|     229253|  2018-04-10|\n",
      "|       Make You Stay|      Do It for Love|['Daryl Hall & Jo...|     221174|  2018-04-10|\n",
      "+--------------------+--------------------+--------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "dataset with added 'song_length_minutes' and 'long_song' columns:\n",
      "+--------------------+--------------------+--------------------+-----------+------------+-------------------+---------+\n",
      "|                name|               album|             artists|duration_ms|release_date|song_length_minutes|long_song|\n",
      "+--------------------+--------------------+--------------------+-----------+------------+-------------------+---------+\n",
      "|             Testify|The Battle Of Los...|['Rage Against Th...|     210133|  1999-11-02|             3.5022|        0|\n",
      "|     Guerrilla Radio|The Battle Of Los...|['Rage Against Th...|     206200|  1999-11-02|             3.4367|        0|\n",
      "|    Calm Like a Bomb|The Battle Of Los...|['Rage Against Th...|     298893|  1999-11-02|             4.9816|        0|\n",
      "|           Mic Check|The Battle Of Los...|['Rage Against Th...|     213640|  1999-11-02|             3.5607|        0|\n",
      "|Sleep Now In the ...|The Battle Of Los...|['Rage Against Th...|     205600|  1999-11-02|             3.4267|        0|\n",
      "|Born of a Broken Man|The Battle Of Los...|['Rage Against Th...|     280960|  1999-11-02|             4.6827|        0|\n",
      "|      Born As Ghosts|The Battle Of Los...|['Rage Against Th...|     202040|  1999-11-02|             3.3673|        0|\n",
      "|               Maria|The Battle Of Los...|['Rage Against Th...|     228093|  1999-11-02|             3.8016|        0|\n",
      "|Voice of the Voic...|The Battle Of Los...|['Rage Against Th...|     151573|  1999-11-02|             2.5262|        0|\n",
      "|New Millennium Homes|The Battle Of Los...|['Rage Against Th...|     224933|  1999-11-02|             3.7489|        0|\n",
      "|   Ashes In the Fall|The Battle Of Los...|['Rage Against Th...|     277267|  1999-11-02|             4.6211|        0|\n",
      "| War Within a Breath|The Battle Of Los...|['Rage Against Th...|     216427|  1999-11-02|             3.6071|        0|\n",
      "|           Bombtrack|Rage Against The ...|['Rage Against Th...|     243760|  1992-11-03|             4.0627|        0|\n",
      "| Killing In the Name|Rage Against The ...|['Rage Against Th...|     313667|  1992-11-03|             5.2278|        0|\n",
      "| Take the Power Back|Rage Against The ...|['Rage Against Th...|     335840|  1992-11-03|             5.5973|        0|\n",
      "|  Settle for Nothing|Rage Against The ...|['Rage Against Th...|     287333|  1992-11-03|             4.7889|        0|\n",
      "|  Bullet In the Head|Rage Against The ...|['Rage Against Th...|     307067|  1992-11-03|             5.1178|        0|\n",
      "|     Know Your Enemy|Rage Against The ...|['Rage Against Th...|     294693|  1992-11-03|             4.9116|        0|\n",
      "|             Wake Up|Rage Against The ...|['Rage Against Th...|     364133|  1992-11-03|             6.0689|        0|\n",
      "|    Fistful of Steel|Rage Against The ...|['Rage Against Th...|     331107|  1992-11-03|             5.5184|        0|\n",
      "+--------------------+--------------------+--------------------+-----------+------------+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of 1 values in the 'long_song' column: 7992\n",
      "\n",
      "--------------------------------------------------------     STEP 4     --------------------------------------------------------\n",
      "\n",
      "Exploded DataFrame with Each Artist in a Separate Row:\n",
      "+--------------------+--------------------+--------------------+-----------+------------+\n",
      "|                name|               album|              artist|duration_ms|release_date|\n",
      "+--------------------+--------------------+--------------------+-----------+------------+\n",
      "|             Testify|The Battle Of Los...|['Rage Against Th...|     210133|  1999-11-02|\n",
      "|     Guerrilla Radio|The Battle Of Los...|['Rage Against Th...|     206200|  1999-11-02|\n",
      "|    Calm Like a Bomb|The Battle Of Los...|['Rage Against Th...|     298893|  1999-11-02|\n",
      "|           Mic Check|The Battle Of Los...|['Rage Against Th...|     213640|  1999-11-02|\n",
      "|Sleep Now In the ...|The Battle Of Los...|['Rage Against Th...|     205600|  1999-11-02|\n",
      "|Born of a Broken Man|The Battle Of Los...|['Rage Against Th...|     280960|  1999-11-02|\n",
      "|      Born As Ghosts|The Battle Of Los...|['Rage Against Th...|     202040|  1999-11-02|\n",
      "|               Maria|The Battle Of Los...|['Rage Against Th...|     228093|  1999-11-02|\n",
      "|Voice of the Voic...|The Battle Of Los...|['Rage Against Th...|     151573|  1999-11-02|\n",
      "|New Millennium Homes|The Battle Of Los...|['Rage Against Th...|     224933|  1999-11-02|\n",
      "|   Ashes In the Fall|The Battle Of Los...|['Rage Against Th...|     277267|  1999-11-02|\n",
      "| War Within a Breath|The Battle Of Los...|['Rage Against Th...|     216427|  1999-11-02|\n",
      "|           Bombtrack|Rage Against The ...|['Rage Against Th...|     243760|  1992-11-03|\n",
      "| Killing In the Name|Rage Against The ...|['Rage Against Th...|     313667|  1992-11-03|\n",
      "| Take the Power Back|Rage Against The ...|['Rage Against Th...|     335840|  1992-11-03|\n",
      "|  Settle for Nothing|Rage Against The ...|['Rage Against Th...|     287333|  1992-11-03|\n",
      "|  Bullet In the Head|Rage Against The ...|['Rage Against Th...|     307067|  1992-11-03|\n",
      "|     Know Your Enemy|Rage Against The ...|['Rage Against Th...|     294693|  1992-11-03|\n",
      "|             Wake Up|Rage Against The ...|['Rage Against Th...|     364133|  1992-11-03|\n",
      "|    Fistful of Steel|Rage Against The ...|['Rage Against Th...|     331107|  1992-11-03|\n",
      "+--------------------+--------------------+--------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "--------------------------------------------------------     STEP 5     --------------------------------------------------------\n",
      "\n",
      "Top 10 Songs based on Valence:\n",
      "+--------------------+--------------------+--------------------+-----------+------------+\n",
      "|                name|               album|             artists|duration_ms|release_date|\n",
      "+--------------------+--------------------+--------------------+-----------+------------+\n",
      "| Clean Shirt Reprise|      The Third Rail|   ['Railroad Jerk']|      33733|  1996-10-08|\n",
      "|         Dain's Mill|The Dark Peak and...|     ['Bella Hardy']|      69773|  2012-05-06|\n",
      "|               Genie|History: Mission ...|  ['The Gravel Pit']|      25867|  1997-01-01|\n",
      "|           Crag Lake|          Buck Fever|   ['Estradasphere']|      48147|  2001-01-01|\n",
      "|       In This World|            Shine On|             ['Lea']|     379173|  2005-08-11|\n",
      "|         Breakbeat 4|Best Of Neverendi...|        ['Dj Swamp']|      32000|  2005-08-18|\n",
      "|Give Thanks in Al...|Sing the Word Fro...|['The Harrow Fami...|      61373|  2001-12-04|\n",
      "|Let It Snoki Doki...|         8-Bit Jesus|  ['Doctor Octoroc']|      66960|  2008-12-20|\n",
      "|   Itsy Bitsy Spider|Rhymin' to the Be...|   ['Jack Hartmann']|     100000|  1996-01-01|\n",
      "|The Drunken Landlady|    The Family Album|   ['The McCarthys']|      79960|  2010-05-08|\n",
      "+--------------------+--------------------+--------------------+-----------+------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--------------------------------------------------------     STEP 1     --------------------------------------------------------\")\n",
    "# Step 1: Check the Schema\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spotify Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read the parquet file into a DataFrame\n",
    "df = spark.read.parquet(\"spotify.parquet\")\n",
    "\n",
    "# Print the schema\n",
    "df.printSchema()\n",
    "\n",
    "print(\"\\n--------------------------------------------------------     STEP 2     --------------------------------------------------------\")\n",
    "# Step 2: Preprocess Columns\n",
    "\n",
    "# Convert 'release_date' to date type\n",
    "df = df.withColumn('release_date', to_date(df['release_date']))\n",
    "column_data_type = df.schema['release_date'].dataType\n",
    "print(\"Data type of column '{}': {}\".format('release_date', column_data_type))\n",
    "\n",
    "print(\"\\n--------------------------------------------------------     STEP 3     --------------------------------------------------------\")\n",
    "# Step 3: Aggregation, Filtering, and Transformation\n",
    "\n",
    "# Aggregate statistics for danceability and energy features by year\n",
    "aggregate_statistics = df.groupBy('year').agg(\n",
    "    format_number(min('danceability'), 4).alias('min_danceability'),\n",
    "    format_number(max('danceability'), 4).alias('max_danceability'),\n",
    "    format_number(median('danceability'), 4).alias('median_danceability'),\n",
    "    format_number(avg('danceability'), 4).alias('avg_danceability'),\n",
    "    format_number(min('energy'), 4).alias('min_energy'),\n",
    "    format_number(max('energy'), 4).alias('max_energy'),\n",
    "    format_number(median('energy'), 4).alias('median_energy'),\n",
    "    format_number(avg('energy'), 4).alias('avg_energy'),\n",
    "    format_number(avg('duration_ms'), 4).alias('avg_duration_ms')\n",
    ")\n",
    "print(\"\\nAverage Characteristics of Songs Per Year:\")\n",
    "aggregate_statistics.show()\n",
    "\n",
    "# Filter the dataset to exclude the songs with explicit content\n",
    "non_explicit_songs = df.select('name', 'album', 'artists', 'duration_ms', 'release_date').filter(df['explicit'] == False)\n",
    "print(\"\\ndataset excluding explicit songs:\")\n",
    "non_explicit_songs.show()\n",
    "\n",
    "# Convert duration from milliseconds to minutes\n",
    "df_added = df.select('name', 'album', 'artists', 'duration_ms', 'release_date').withColumn('song_length_minutes', format_number(col('duration_ms') / 60000, 4))\n",
    "\n",
    "# Create a new binary feature 'long_song' indicating whether the song duration is above a certain threshold (e.g., 15 minutes).\n",
    "threshold = 15 * 60 * 1000  # 5 minutes in milliseconds\n",
    "df_added = df_added.withColumn('long_song', when(df['duration_ms'] > threshold, 1).otherwise(0))\n",
    "\n",
    "print(\"\\ndataset with added \\'song_length_minutes\\' and \\'long_song\\' columns:\")\n",
    "df_added.show()\n",
    "\n",
    "# Count the number of long songs in the dataset\n",
    "count_ones = df_added.filter(col('long_song') == 1).count()\n",
    "print(\"\\nNumber of 1 values in the 'long_song' column:\", count_ones)\n",
    "\n",
    "print(\"\\n--------------------------------------------------------     STEP 4     --------------------------------------------------------\")\n",
    "# Step 4: Dealing with Array Columns\n",
    "\n",
    "# For example, if we want to explode the 'artists' array to get each artist in a separate row\n",
    "# Split the 'artists' string by comma and create an array\n",
    "df_with_array = df.withColumn('artists_array', split(df['artists'], ', '))\n",
    "\n",
    "# Explode the array to get each artist in a separate row\n",
    "df_exploded = df_with_array.withColumn('artist', explode(df_with_array['artists_array']))\n",
    "\n",
    "# Drop the intermediate 'artists_array' column\n",
    "df_exploded = df_exploded.drop('artists_array')\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "print(\"\\nExploded DataFrame with Each Artist in a Separate Row:\")\n",
    "df_exploded = df_exploded.select('name', 'album', 'artist', 'duration_ms', 'release_date')\n",
    "df_exploded.show()\n",
    "\n",
    "print(\"\\n--------------------------------------------------------     STEP 5     --------------------------------------------------------\")\n",
    "# Step 5: Top-K Records\n",
    "\n",
    "# For example, let's find the top 10 songs based on valence\n",
    "top_songs = df.select('name', 'album', 'artists', 'duration_ms', 'release_date').orderBy(df['valence'].desc()).limit(10)\n",
    "print(\"\\nTop 10 Songs based on Valence:\")\n",
    "top_songs.show()\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T19:02:05.657178500Z",
     "start_time": "2024-04-17T19:02:02.544502Z"
    }
   },
   "id": "7e14a3d0ad1a0faf"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T19:00:48.478894400Z",
     "start_time": "2024-04-17T19:00:48.475376400Z"
    }
   },
   "id": "12069e93b25b74b2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
